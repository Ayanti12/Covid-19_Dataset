{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d107fa57-1ded-40f9-99cb-257e2d3da8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'covid_project_dataset.csv' loaded successfully.\n",
      "Initial shape: (411804, 10)\n",
      "\n",
      "Initial DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 411804 entries, 0 to 411803\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   date              411804 non-null  object \n",
      " 1   country           411804 non-null  object \n",
      " 2   total_cases       411804 non-null  float64\n",
      " 3   new_cases         411804 non-null  float64\n",
      " 4   total_deaths      411804 non-null  float64\n",
      " 5   new_deaths        411804 non-null  float64\n",
      " 6   total_recoveries  411804 non-null  int64  \n",
      " 7   new_recoveries    411804 non-null  int64  \n",
      " 8   active_cases      411804 non-null  float64\n",
      " 9   population        411804 non-null  int64  \n",
      "dtypes: float64(5), int64(3), object(2)\n",
      "memory usage: 31.4+ MB\n",
      "\n",
      "Initial DataFrame Head:\n",
      "         date      country  total_cases  new_cases  total_deaths  new_deaths  \\\n",
      "0  2020-01-05  Afghanistan          0.0        0.0           0.0         0.0   \n",
      "1  2020-01-06  Afghanistan          0.0        0.0           0.0         0.0   \n",
      "2  2020-01-07  Afghanistan          0.0        0.0           0.0         0.0   \n",
      "3  2020-01-08  Afghanistan          0.0        0.0           0.0         0.0   \n",
      "4  2020-01-09  Afghanistan          0.0        0.0           0.0         0.0   \n",
      "\n",
      "   total_recoveries  new_recoveries  active_cases  population  \n",
      "0                 0               0           0.0    41128772  \n",
      "1                 0               0           0.0    41128772  \n",
      "2                 0               0           0.0    41128772  \n",
      "3                 0               0           0.0    41128772  \n",
      "4                 0               0           0.0    41128772  \n",
      "\n",
      "Columns renamed: {'date': 'Date', 'country': 'Country/Region', 'total_cases': 'Confirmed', 'total_deaths': 'Deaths', 'total_recoveries': 'Recovered'}\n",
      "Converted 'Date' column to datetime.\n",
      "Missing values in 'Confirmed' handled (filled with 0).\n",
      "Missing values in 'Deaths' handled (filled with 0).\n",
      "Missing values in 'Recovered' handled (filled with 0).\n",
      "No duplicate rows found based on 'Date' and 'Country/Region'.\n",
      "\n",
      "DataFrame shape after initial cleaning: (411804, 5)\n",
      "\n",
      "Cleaned DataFrame Head (pre-Section 2 processing):\n",
      "        Date Country/Region  Confirmed  Deaths  Recovered\n",
      "0 2020-01-05    Afghanistan        0.0     0.0          0\n",
      "1 2020-01-06    Afghanistan        0.0     0.0          0\n",
      "2 2020-01-07    Afghanistan        0.0     0.0          0\n",
      "3 2020-01-08    Afghanistan        0.0     0.0          0\n",
      "4 2020-01-09    Afghanistan        0.0     0.0          0\n",
      "\n",
      "--- Starting Section 2: Data Processing and Analysis ---\n",
      "\n",
      "--- Statistical Analysis (NumPy/Pandas) ---\n",
      "Overall Death Rate (across all data points): 1.10%\n",
      "Mean Confirmed Cases (non-zero): 7929560.40\n",
      "Median Confirmed Cases (non-zero): 86919.00\n",
      "Std Dev Confirmed Cases (non-zero): 46411109.07\n",
      "Correlation between Confirmed and Deaths (non-zero cases): 0.9455\n",
      "\n",
      "--- Growth Rate Calculation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayanti\\AppData\\Local\\Temp\\ipykernel_18392\\1227119811.py:152: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Growth_Rate_Confirmed'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Daily new cases and growth rate calculated (head for example):\n",
      "        Date Country/Region  Confirmed  Daily_New_Confirmed  \\\n",
      "0 2020-01-05    Afghanistan        0.0                  0.0   \n",
      "1 2020-01-06    Afghanistan        0.0                  0.0   \n",
      "2 2020-01-07    Afghanistan        0.0                  0.0   \n",
      "3 2020-01-08    Afghanistan        0.0                  0.0   \n",
      "4 2020-01-09    Afghanistan        0.0                  0.0   \n",
      "\n",
      "   Growth_Rate_Confirmed  \n",
      "0                    0.0  \n",
      "1                    0.0  \n",
      "2                    0.0  \n",
      "3                    0.0  \n",
      "4                    0.0  \n",
      "\n",
      "--- Data Aggregation (groupby/pivot_table) ---\n",
      "\n",
      "Total cases per country (latest data, head):\n",
      "   Country/Region  Latest_Confirmed  Latest_Deaths  Latest_Recovered\n",
      "0     Afghanistan          235214.0         7998.0                 0\n",
      "1          Africa        13145380.0       259117.0                 0\n",
      "2         Albania          335047.0         3605.0                 0\n",
      "3         Algeria          272139.0         6881.0                 0\n",
      "4  American Samoa            8359.0           34.0                 0\n",
      "\n",
      "Pivot table of Confirmed Cases by Date and (Sample) Country (first 5 rows, first 5 countries):\n",
      "Country/Region  Afghanistan  Africa  Albania  Algeria  American Samoa\n",
      "Date                                                                 \n",
      "2020-01-05              0.0     0.0      0.0      0.0             0.0\n",
      "2020-01-06              0.0     0.0      0.0      0.0             0.0\n",
      "2020-01-07              0.0     0.0      0.0      0.0             0.0\n",
      "2020-01-08              0.0     0.0      0.0      0.0             0.0\n",
      "2020-01-09              0.0     0.0      0.0      0.0             0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the file path for the uploaded CSV\n",
    "file_path = 'covid_project_dataset.csv'\n",
    "\n",
    "# --- Section 1: Data Collection and Cleaning (adapted for the new dataset) ---\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Dataset '{file_path}' loaded successfully.\")\n",
    "    print(f\"Initial shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{file_path}' not found. Please ensure the CSV file is in the correct directory.\")\n",
    "    # In a real notebook, you might stop execution or provide an example DataFrame\n",
    "    df = pd.DataFrame() # Create an empty DataFrame to prevent errors later\n",
    "\n",
    "if not df.empty:\n",
    "    # Display basic info and head for inspection\n",
    "    print(\"\\nInitial DataFrame Info:\")\n",
    "    df.info()\n",
    "    print(\"\\nInitial DataFrame Head:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Standardize column names (adjust these based on actual column names in your CSV)\n",
    "    # The 'covid_project_dataset.csv' appears to have 'date', 'country', 'total_cases', 'total_deaths', 'total_recoveries'\n",
    "    column_mapping = {\n",
    "        'date': 'Date',\n",
    "        'country': 'Country/Region',\n",
    "        'total_cases': 'Confirmed',\n",
    "        'total_deaths': 'Deaths',\n",
    "        'total_recoveries': 'Recovered'\n",
    "    }\n",
    "\n",
    "    # Apply renaming only if the column exists\n",
    "    renamed_columns = {}\n",
    "    for old_name, new_name in column_mapping.items():\n",
    "        if old_name in df.columns and old_name != new_name:\n",
    "            renamed_columns[old_name] = new_name\n",
    "    df.rename(columns=renamed_columns, inplace=True)\n",
    "    if renamed_columns:\n",
    "        print(f\"\\nColumns renamed: {renamed_columns}\")\n",
    "\n",
    "    # Ensure 'Date' column is datetime\n",
    "    if 'Date' in df.columns:\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df.dropna(subset=['Date'], inplace=True) # Drop rows where Date conversion failed\n",
    "        print(\"Converted 'Date' column to datetime.\")\n",
    "    else:\n",
    "        print(\"Warning: 'Date' column not found. Date-based analysis might be limited.\")\n",
    "\n",
    "\n",
    "    # Handle missing numerical values (Confirmed, Deaths, Recovered) by filling with 0.\n",
    "    # It's crucial for cumulative counts.\n",
    "    for col in ['Confirmed', 'Deaths', 'Recovered']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0.0 # Add column and fill with 0 if missing\n",
    "            print(f\"'{col}' column was missing and added with 0.0 values.\")\n",
    "        else:\n",
    "            # Convert to numeric first, then fill NaNs\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "            print(f\"Missing values in '{col}' handled (filled with 0).\")\n",
    "\n",
    "    # Drop duplicates based on 'Date' and 'Country/Region' to ensure unique daily records\n",
    "    initial_rows_count = df.shape[0]\n",
    "    if 'Date' in df.columns and 'Country/Region' in df.columns:\n",
    "        df.drop_duplicates(subset=['Date', 'Country/Region'], inplace=True)\n",
    "        rows_after_duplicates = df.shape[0]\n",
    "        if initial_rows_count > rows_after_duplicates:\n",
    "            print(f\"Removed {initial_rows_count - rows_after_duplicates} duplicate rows based on 'Date' and 'Country/Region'.\")\n",
    "        else:\n",
    "            print(\"No duplicate rows found based on 'Date' and 'Country/Region'.\")\n",
    "    else:\n",
    "        print(\"Warning: Skipping duplicate removal by Date and Country/Region as one or both columns are missing.\")\n",
    "        df.drop_duplicates(inplace=True) # Fallback to general duplicate removal\n",
    "        if initial_rows_count > df.shape[0]:\n",
    "            print(f\"Removed {initial_rows_count - df.shape[0]} duplicate rows (general).\")\n",
    "\n",
    "    # Keep only the essential columns needed for Section 2 processing\n",
    "    # Add any other columns you might want for later analysis (e.g., 'population')\n",
    "    final_cols_to_keep = ['Date', 'Country/Region', 'Confirmed', 'Deaths', 'Recovered']\n",
    "    # Filter for columns that actually exist in the DataFrame after renaming and adding\n",
    "    df = df[[col for col in final_cols_to_keep if col in df.columns]]\n",
    "\n",
    "    print(f\"\\nDataFrame shape after initial cleaning: {df.shape}\")\n",
    "    print(\"\\nCleaned DataFrame Head (pre-Section 2 processing):\")\n",
    "    print(df.head())\n",
    "\n",
    "    # --- Section 2: Data Processing and Analysis ---\n",
    "    print(\"\\n--- Starting Section 2: Data Processing and Analysis ---\")\n",
    "\n",
    "    # Ensure necessary columns exist for the core analysis steps in Section 2\n",
    "    required_cols_for_analysis = ['Confirmed', 'Deaths', 'Country/Region', 'Date']\n",
    "    if not all(col in df.columns for col in required_cols_for_analysis):\n",
    "        missing_cols = [col for col in required_cols_for_analysis if col not in df.columns]\n",
    "        print(f\"Error: Missing one or more required columns for core analysis ({missing_cols}). Cannot proceed with Section 2 fully.\")\n",
    "        # Attempt to proceed with available columns, but warn the user.\n",
    "    else:\n",
    "        # Sort data for correct daily differences\n",
    "        df = df.sort_values(by=['Country/Region', 'Date'])\n",
    "\n",
    "        # 1. Use NumPy/Pandas to perform statistical analysis\n",
    "        print(\"\\n--- Statistical Analysis (NumPy/Pandas) ---\")\n",
    "\n",
    "        # Overall Death Rate (using total sums)\n",
    "        total_confirmed_overall = df['Confirmed'].sum()\n",
    "        total_deaths_overall = df['Deaths'].sum()\n",
    "\n",
    "        if total_confirmed_overall > 0:\n",
    "            overall_death_rate = (total_deaths_overall / total_confirmed_overall) * 100\n",
    "            print(f\"Overall Death Rate (across all data points): {overall_death_rate:.2f}%\")\n",
    "        else:\n",
    "            print(\"No confirmed cases to calculate overall death rate.\")\n",
    "\n",
    "        # Mean, Median, Standard Deviation of Confirmed Cases (for non-zero cases to be meaningful)\n",
    "        df_cases_nonzero = df[df['Confirmed'] > 0]\n",
    "        if not df_cases_nonzero.empty:\n",
    "            print(f\"Mean Confirmed Cases (non-zero): {np.mean(df_cases_nonzero['Confirmed']):.2f}\")\n",
    "            print(f\"Median Confirmed Cases (non-zero): {np.median(df_cases_nonzero['Confirmed']):.2f}\")\n",
    "            print(f\"Std Dev Confirmed Cases (non-zero): {np.std(df_cases_nonzero['Confirmed']):.2f}\")\n",
    "        else:\n",
    "            print(\"No non-zero confirmed cases found for statistical analysis.\")\n",
    "\n",
    "        # Correlation between Confirmed and Deaths (using non-zero cases)\n",
    "        if 'Confirmed' in df_cases_nonzero.columns and 'Deaths' in df_cases_nonzero.columns:\n",
    "            correlation = df_cases_nonzero['Confirmed'].corr(df_cases_nonzero['Deaths'])\n",
    "            print(f\"Correlation between Confirmed and Deaths (non-zero cases): {correlation:.4f}\")\n",
    "        else:\n",
    "            print(\"Not enough non-zero confirmed/deaths data to calculate correlation.\")\n",
    "\n",
    "\n",
    "        # 2. Group data by country and calculate daily/weekly growth rates.\n",
    "        print(\"\\n--- Growth Rate Calculation ---\")\n",
    "\n",
    "        # Calculate daily new cases and deaths (using .diff() as the safest general method)\n",
    "        df['Daily_New_Confirmed'] = df.groupby('Country/Region')['Confirmed'].diff().fillna(0)\n",
    "        df['Daily_New_Deaths'] = df.groupby('Country/Region')['Deaths'].diff().fillna(0)\n",
    "        df['Daily_New_Recovered'] = df.groupby('Country/Region')['Recovered'].diff().fillna(0)\n",
    "\n",
    "        # Ensure Daily_New values are non-negative, as diff() can produce negative if data corrections occur\n",
    "        df['Daily_New_Confirmed'] = df['Daily_New_Confirmed'].clip(lower=0)\n",
    "        df['Daily_New_Deaths'] = df['Daily_New_Deaths'].clip(lower=0)\n",
    "        df['Daily_New_Recovered'] = df['Daily_New_Recovered'].clip(lower=0)\n",
    "\n",
    "        # Growth Rate of Confirmed Cases (New cases / Previous day's total cases) * 100\n",
    "        # Need to be careful with previous day's total cases being zero.\n",
    "        df['Previous_Confirmed'] = df.groupby('Country/Region')['Confirmed'].shift(1).fillna(0)\n",
    "        df['Growth_Rate_Confirmed'] = df.apply(lambda row:\n",
    "                                               (row['Daily_New_Confirmed'] / row['Previous_Confirmed']) * 100\n",
    "                                               if row['Previous_Confirmed'] > 0 else 0, axis=1)\n",
    "        # Handle inf/-inf results from division by zero or large swings by converting to NaN then 0\n",
    "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        df['Growth_Rate_Confirmed'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "        print(\"\\nDaily new cases and growth rate calculated (head for example):\")\n",
    "        print(df[['Date', 'Country/Region', 'Confirmed', 'Daily_New_Confirmed', 'Growth_Rate_Confirmed']].head())\n",
    "\n",
    "        # 3. Perform data aggregation using groupby() and pivot_table() methods in Pandas.\n",
    "        print(\"\\n--- Data Aggregation (groupby/pivot_table) ---\")\n",
    "\n",
    "        # Total cases per country (using the maximum recorded values for each country)\n",
    "        # This gives the latest cumulative figures\n",
    "        country_summary = df.groupby('Country/Region').agg(\n",
    "            Latest_Confirmed=('Confirmed', 'max'),\n",
    "            Latest_Deaths=('Deaths', 'max'),\n",
    "            Latest_Recovered=('Recovered', 'max')\n",
    "        ).reset_index()\n",
    "\n",
    "        # Clean up any potential inf/NaN from aggregations\n",
    "        country_summary.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        country_summary.fillna(0, inplace=True)\n",
    "\n",
    "        print(\"\\nTotal cases per country (latest data, head):\")\n",
    "        print(country_summary.head())\n",
    "\n",
    "        # Pivot table for confirmed cases over time by country\n",
    "        # Ensure only one entry per country per date for accurate pivoting.\n",
    "        df_for_pivot = df.drop_duplicates(subset=['Date', 'Country/Region'], keep='last')\n",
    "        # Select a subset of countries for the pivot table preview if there are too many\n",
    "        unique_countries = df_for_pivot['Country/Region'].unique()\n",
    "        # Take first 5 for preview, or fewer if less than 5 unique\n",
    "        countries_for_pivot_preview = unique_countries[:min(5, len(unique_countries))]\n",
    "\n",
    "        # Filter the DataFrame to only include these countries for a manageable pivot table preview\n",
    "        filtered_df_for_pivot = df_for_pivot[df_for_pivot['Country/Region'].isin(countries_for_pivot_preview)]\n",
    "\n",
    "        # Check if there's enough data to pivot\n",
    "        if not filtered_df_for_pivot.empty:\n",
    "            confirmed_pivot = filtered_df_for_pivot.pivot_table(index='Date', columns='Country/Region', values='Confirmed').fillna(0)\n",
    "            print(\"\\nPivot table of Confirmed Cases by Date and (Sample) Country (first 5 rows, first 5 countries):\")\n",
    "            print(confirmed_pivot.iloc[:5, :5]) # Print first 5 rows and first 5 columns for brevity\n",
    "        else:\n",
    "            print(\"\\nNot enough data to create a meaningful pivot table preview for selected countries.\")\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame is empty after initial loading/cleaning. Cannot perform data processing and analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60acf0b1-0509-4947-8e91-242c10be7b27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
